{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "project_2_nn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', size=16)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "icvIZoew6lh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)"
      ],
      "metadata": {
        "id": "RVghVtFq6lh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My Drive/Project2\n",
        "\n",
        "dataset = pd.read_csv('Training.csv')"
      ],
      "metadata": {
        "id": "OzFRWaBL6pH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_size = 6510\n",
        "X_train_raw = dataset[:-test_size]\n",
        "X_test_raw = dataset[-test_size:]\n",
        "\n",
        "#Standardize\n",
        "scaler = StandardScaler()\n",
        "X_train_raw = scaler.fit_transform(X_train_raw)\n",
        "X_test_raw = scaler.transform(X_test_raw)\n",
        "\n",
        "# Normalize both features and labels\n",
        "min_Scaler = MinMaxScaler()\n",
        "X_train_raw = min_Scaler.fit_transform(X_train_raw)\n",
        "X_test_raw = min_Scaler.transform(X_test_raw)"
      ],
      "metadata": {
        "id": "0w-QW5ir6lh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window = 400\n",
        "stride = 25"
      ],
      "metadata": {
        "id": "ICNG_NiS6lh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_sequences(df, target_labels=['Sponginess'], window=200, stride=20, telescope=1):\n",
        "    # Sanity check to avoid runtime errors\n",
        "    assert window % stride == 0\n",
        "    dataset = []\n",
        "    labels = []\n",
        "    temp_df = df.copy()\n",
        "    temp_label = df.copy()\n",
        "    padding_len = len(df)%window\n",
        "\n",
        "    if(padding_len != 0):\n",
        "        # Compute padding length\n",
        "        padding_len = window - len(df)%window\n",
        "        padding = np.zeros((padding_len,temp_df.shape[1]), dtype='float64')\n",
        "        temp_df = np.concatenate((padding,df))\n",
        "        padding = np.zeros((padding_len,temp_label.shape[1]), dtype='float64')\n",
        "        temp_label = np.concatenate((padding,temp_label))\n",
        "        assert len(temp_df) % window == 0\n",
        "\n",
        "    for idx in np.arange(0,len(temp_df)-window-telescope,stride):\n",
        "        dataset.append(temp_df[idx:idx+window])\n",
        "        labels.append(temp_label[idx+window:idx+window+telescope])\n",
        "\n",
        "    dataset = np.array(dataset)\n",
        "    labels = np.array(labels)\n",
        "    return dataset, labels"
      ],
      "metadata": {
        "id": "25uEpWoU6lh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_labels = dataset.columns\n",
        "telescope = 20"
      ],
      "metadata": {
        "id": "HrLirZ7K6lh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = build_sequences(X_train_raw, target_labels, window, stride, telescope)\n",
        "X_test, y_test = build_sequences(X_test_raw, target_labels, window, stride, telescope)"
      ],
      "metadata": {
        "id": "fRk1HDxp6lh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_LSTM_model(input_shape, output_shape): \n",
        "\n",
        "    #ENCODER\n",
        "    encoder_inputs = tfkl.Input(shape=input_shape)\n",
        "    conv_outputs = tfkl.Conv1D(128, 3, padding='same', activation='relu')(encoder_inputs)\n",
        "    maxpool_outputs = tfkl.MaxPool1D()(conv_outputs)\n",
        "    encoder_outputs1 = tfkl.Bidirectional(tfkl.LSTM(256,return_sequences = True, return_state=True))(maxpool_outputs)\n",
        "    encoder_states1 = encoder_outputs1[1:]\n",
        "    encoder_l2 = tfkl.Bidirectional(tfkl.LSTM(128, return_state=True))\n",
        "    encoder_outputs2 = encoder_l2(encoder_outputs1[0])\n",
        "    encoder_states2 = encoder_outputs2[1:]\n",
        "\n",
        "    #DECODER\n",
        "    decoder_inputs = tfkl.RepeatVector(output_shape[0])(encoder_outputs2[0])\n",
        "    decoder_l1 = tfkl.Bidirectional(tfkl.LSTM(256, return_sequences=True))(decoder_inputs,initial_state = encoder_states1)\n",
        "    decoder_l2 = tfkl.Bidirectional(tfkl.LSTM(128, return_sequences=True))(decoder_l1,initial_state = encoder_states2)\n",
        "    dropout_l = tfkl.Dropout(0.2)(decoder_l2)\n",
        "    decoder_outputs2 = tfkl.TimeDistributed(tfkl.Dense(output_shape[1], activation='relu'))(dropout_l)\n",
        "\n",
        "    #CREATION OF THE MODEL\n",
        "    model = tf.keras.models.Model(encoder_inputs, decoder_outputs2)\n",
        "\n",
        "    loss = tf.keras.losses.MeanSquaredError()\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    model.compile(loss=loss, optimizer=optimizer, metrics=['mse'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "WlaxoZQp6lh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (window, 7)\n",
        "output_shape = (telescope, 7)\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 100"
      ],
      "metadata": {
        "id": "sR0vbQRg6lh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_LSTM_model(input_shape, output_shape)\n",
        "model.summary()\n",
        "tfk.utils.plot_model(model, expand_nested=True)"
      ],
      "metadata": {
        "id": "0Em594NB6lh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    x = X_train,\n",
        "    y = y_train,\n",
        "    batch_size = batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_split=.1,\n",
        "    callbacks = [\n",
        "        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True),\n",
        "        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-5)\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.save('model_cnn_lstm_dropout_400_25_20')"
      ],
      "metadata": {
        "id": "9i9ArncBIGD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize the predictions"
      ],
      "metadata": {
        "id": "p_xy5kEgG8re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg_telescope = 900\n",
        "X_test_reg, y_test_reg = build_sequences(X_test_raw, target_labels, window, stride, reg_telescope)"
      ],
      "metadata": {
        "id": "6fY0LBLg6liB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Autoregressive Forecasting\n",
        "reg_predictions = np.array([])\n",
        "\n",
        "y_test_reg = y_test_reg[200:200+1,:,:]\n",
        "X_test_reg = X_test_reg[200:200+1,:,:]\n",
        "\n",
        "\n",
        "X_temp = X_test_reg\n",
        "for reg in range(0,reg_telescope,telescope):\n",
        "    pred_temp = model.predict(X_temp)\n",
        "    if(len(reg_predictions)==0):\n",
        "        reg_predictions = pred_temp\n",
        "    else:\n",
        "        reg_predictions = np.concatenate((reg_predictions, pred_temp), axis=1)\n",
        "    X_temp = np.concatenate((X_temp[:,telescope:,:],pred_temp), axis=1)"
      ],
      "metadata": {
        "id": "TKhV64vAm3lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inspect_multivariate_prediction(X, y, pred, columns, telescope, idx=None):\n",
        "    if(idx==None):\n",
        "        idx=np.random.randint(0,len(X))\n",
        "\n",
        "    figs, axs = plt.subplots(len(columns), 1, sharex=True, figsize=(17,17))\n",
        "    for i, col in enumerate(columns):\n",
        "        axs[i].plot(np.arange(len(X[0,:,i])), X[idx,:,i])\n",
        "        axs[i].plot(np.arange(len(X[0,:,i]), len(X_train[0,:,i])+telescope), y[idx,:,i], color='orange')\n",
        "        axs[i].plot(np.arange(len(X[0,:,i]), len(X_train[0,:,i])+telescope), pred[idx,:,i], color='green')\n",
        "        axs[i].set_title(col)\n",
        "        axs[i].set_ylim(0,1)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "PNSXF9m26liB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inspect_multivariate_prediction(X_test_reg, y_test_reg, reg_predictions, target_labels, reg_telescope)"
      ],
      "metadata": {
        "id": "fDjLy8g26liC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}